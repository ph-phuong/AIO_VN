{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15748,
     "status": "ok",
     "timestamp": 1733743607717,
     "user": {
      "displayName": "Phuong Nguyen",
      "userId": "11974806599025701743"
     },
     "user_tz": -420
    },
    "id": "_7Gcu-fRXvQw"
   },
   "outputs": [],
   "source": [
    "# 1. Import các thư viện cần thiết\n",
    "import random\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "import torch # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "import torchvision # type: ignore\n",
    "import torchvision.transforms as transforms # type: ignore\n",
    "from torch import nn # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader, random_split # type: ignore\n",
    "from torchvision.datasets import FashionMNIST # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733743607717,
     "user": {
      "displayName": "Phuong Nguyen",
      "userId": "11974806599025701743"
     },
     "user_tz": -420
    },
    "id": "QOCimfFgavaW"
   },
   "outputs": [],
   "source": [
    "# 2. Xác định phần cứng và cố định tham số ngẫu nhiên\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4970,
     "status": "ok",
     "timestamp": 1733743612682,
     "user": {
      "displayName": "Phuong Nguyen",
      "userId": "11974806599025701743"
     },
     "user_tz": -420
    },
    "id": "lvxlHynKksSC",
    "outputId": "ccede360-2385-4524-87b6-6d9c94e49267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 306kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.60MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 3.54MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Tải bộ dữ liệu\n",
    "train_dataset = FashionMNIST(\n",
    "                            root='./data',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "test_dataset = FashionMNIST(\n",
    "                            root='./data',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733743612682,
     "user": {
      "displayName": "Phuong Nguyen",
      "userId": "11974806599025701743"
     },
     "user_tz": -420
    },
    "id": "wg6PbiO4uzhg",
    "outputId": "5c13a2cf-9aa6-42f9-e280-81375f50f03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 54000\n",
      "Val size: 6000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "# 4. Chia bộ dữ liệu train/val/test\n",
    "batch_size = 64\n",
    "train_ratio = 0.9\n",
    "train_size = int(train_ratio * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train size: {len(train_subset)}\")\n",
    "print(f\"Val size: {len(val_subset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733743612682,
     "user": {
      "displayName": "Phuong Nguyen",
      "userId": "11974806599025701743"
     },
     "user_tz": -420
    },
    "id": "6g-24Ot811q5"
   },
   "outputs": [],
   "source": [
    "# 5. Xây dựng mô hình MLP\n",
    "# Xây dựng các mô hình thành phần\n",
    "class MPL1Layer(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(MPL1Layer, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, output_dims)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.05)\n",
    "            nn.init.constant_(module.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n",
    "class MLP2Layers(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super(MLP2Layers, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dims, output_dims)\n",
    "        self.layer2 = nn.Linear(output_dims, output_dims)\n",
    "\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.05)\n",
    "                nn.init.constant_(module.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = self.layer2(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "\n",
    "# Khởi tạo các module thành phần\n",
    "first = MLP2Layers(input_dims=784, output_dims=128)\n",
    "second = MLP2Layers(input_dims=128, output_dims=128)\n",
    "third = MLP2Layers(input_dims=128, output_dims=128)\n",
    "fourth = MLP2Layers(input_dims=128, output_dims=128)\n",
    "\n",
    "lr = 1e-2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Giai đoạn 1 - Huấn luyện chỉ với thành phần đầu tiên\n",
    "model = nn.Sequential(\n",
    "            first,\n",
    "            nn.Linear(128,10)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAqOzIwEjYxw",
    "outputId": "edf4c266-fba2-40b8-9544-9f4bd7fcace5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/40, Train_Loss: 2.2967, Train_Acc: 0.1374, Val_Loss: 2.2832, Val_Acc: 0.2788\n",
      "EPOCH 2/40, Train_Loss: 2.2620, Train_Acc: 0.2435, Val_Loss: 2.2342, Val_Acc: 0.1902\n",
      "EPOCH 3/40, Train_Loss: 2.1589, Train_Acc: 0.3580, Val_Loss: 2.0500, Val_Acc: 0.4265\n",
      "EPOCH 4/40, Train_Loss: 1.8801, Train_Acc: 0.4116, Val_Loss: 1.7310, Val_Acc: 0.4555\n",
      "EPOCH 5/40, Train_Loss: 1.6126, Train_Acc: 0.4815, Val_Loss: 1.5188, Val_Acc: 0.4997\n",
      "EPOCH 6/40, Train_Loss: 1.4241, Train_Acc: 0.5441, Val_Loss: 1.3549, Val_Acc: 0.5630\n",
      "EPOCH 7/40, Train_Loss: 1.2787, Train_Acc: 0.5825, Val_Loss: 1.2330, Val_Acc: 0.5930\n",
      "EPOCH 8/40, Train_Loss: 1.1704, Train_Acc: 0.6042, Val_Loss: 1.1407, Val_Acc: 0.6095\n",
      "EPOCH 9/40, Train_Loss: 1.0898, Train_Acc: 0.6193, Val_Loss: 1.0739, Val_Acc: 0.5967\n",
      "EPOCH 10/40, Train_Loss: 1.0280, Train_Acc: 0.6278, Val_Loss: 1.0176, Val_Acc: 0.6347\n",
      "EPOCH 11/40, Train_Loss: 0.9775, Train_Acc: 0.6429, Val_Loss: 0.9721, Val_Acc: 0.6392\n",
      "EPOCH 12/40, Train_Loss: 0.9345, Train_Acc: 0.6540, Val_Loss: 0.9319, Val_Acc: 0.6553\n",
      "EPOCH 13/40, Train_Loss: 0.8963, Train_Acc: 0.6663, Val_Loss: 0.8956, Val_Acc: 0.6662\n"
     ]
    }
   ],
   "source": [
    "# 6. Huấn luyện mô hình\n",
    "epochs = 40\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Val_Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miZ2JqF1wwkL"
   },
   "outputs": [],
   "source": [
    "# Giai đoạn 2 - Thêm thành phần thứ hai\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = nn.Sequential(\n",
    "            first,\n",
    "            second,\n",
    "            nn.Linear(128,10)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4i7wnpMQw7ds"
   },
   "outputs": [],
   "source": [
    "# 6. Huấn luyện mô hình\n",
    "epochs = 40\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Val_Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RJWTjkiw-7U"
   },
   "outputs": [],
   "source": [
    "# Giai đoạn 3 - Thêm thành phần thứ ba\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in second.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model= nn.Sequential(\n",
    "            first,\n",
    "            second,\n",
    "            third,\n",
    "            nn.Linear(128,10)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IgsWL4SxFj8"
   },
   "outputs": [],
   "source": [
    "# 6. Huấn luyện mô hình\n",
    "epochs = 40\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Val_Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sK-BVKpSxIV7"
   },
   "outputs": [],
   "source": [
    "# Giai đoạn 4 - Mở khóa toàn bộ thành phần\n",
    "for param in first.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in second.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in third.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = nn.Sequential(\n",
    "            first,\n",
    "            second,\n",
    "            third,\n",
    "            fourth,\n",
    "            nn.Linear(128,10)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nTK_2QDnxMlm"
   },
   "outputs": [],
   "source": [
    "# 6. Huấn luyện mô hình\n",
    "epochs = 40\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "train_acc_lst = []\n",
    "val_acc_lst = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    count = 0\n",
    "    model.train()\n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(outputs, 1) == y_train).sum().item()\n",
    "        count += len(y_train)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_acc /= count\n",
    "    train_acc_lst.append(train_acc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (torch.argmax(outputs, 1) == y_val).sum().item()\n",
    "            count += len(y_val)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_lst.append(val_loss)\n",
    "    val_acc /= count\n",
    "    val_acc_lst.append(val_acc)\n",
    "\n",
    "    print(f\"EPOCH {epoch+1}/{epochs}, Train_Loss: {train_loss:.4f}, Train_Acc: {train_acc:.4f}, Val_Loss: {val_loss:.4f}, Val_Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMRxw1iH11yC"
   },
   "outputs": [],
   "source": [
    "# 7. Trực quan hóa kết quả huấn luyện\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "ax[0, 0].plot(train_loss_lst, color = 'green')\n",
    "ax[0, 0].set(xlabel='Epochs', ylabel='Loss')\n",
    "ax[0, 0].set_title('Training Loss')\n",
    "\n",
    "ax[0, 1].plot(val_loss_lst, color = 'orange')\n",
    "ax[0, 1].set(xlabel='Epochs', ylabel='Loss')\n",
    "ax[0, 1].set_title('Validation Loss')\n",
    "\n",
    "ax[1, 0].plot(train_acc_lst, color = 'green')\n",
    "ax[1, 0].set(xlabel='Epochs', ylabel='Accuracy')\n",
    "ax[1, 0].set_title('Training Accuracy')\n",
    "\n",
    "ax[1, 1].plot(val_acc_lst, color = 'orange')\n",
    "ax[1, 1].set(xlabel='Epochs', ylabel='Accuracy')\n",
    "ax[1, 1].set_title('Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJQ8ZA-Ee6hu"
   },
   "outputs": [],
   "source": [
    "# 8. Đánh giá mô hình\n",
    "test_target = []\n",
    "test_predict = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_test, y_test in test_loader:\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "        outputs = model(X_test)\n",
    "\n",
    "        test_predict.append(outputs.cpu())\n",
    "        test_target.append(y_test.cpu())\n",
    "\n",
    "    test_predict = torch.cat(test_predict)\n",
    "    test_target = torch.cat(test_target)\n",
    "    test_acc = (torch.argmax(test_predict, 1) == test_target).sum().item() / len(test_target)\n",
    "\n",
    "    print('Evaluation on test set:')\n",
    "    print(f'Accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OQv0FrXe6k2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKVYkl1Ae6nl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
