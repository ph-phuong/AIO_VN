{"cells":[{"cell_type":"markdown","metadata":{"id":"NbuSJzIbx4Ei"},"source":["## Auto_MPG_data"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"_7Gcu-fRXvQw","executionInfo":{"status":"ok","timestamp":1731938001355,"user_tz":-420,"elapsed":320,"user":{"displayName":"Phuong Nguyen","userId":"11974806599025701743"}}},"outputs":[],"source":["# 1.Import các thư viện cần thiết\n","import pandas as pd # type: ignore\n","import numpy as np # type: ignore\n","import matplotlib.pyplot as plt # type: ignore\n","import torch # type: ignore\n","import torch.nn as nn # type: ignore\n","from torch.utils.data import Dataset, DataLoader # type: ignore\n","import torch.nn.functional as F # type: ignore\n","\n","from sklearn.model_selection import train_test_split # type: ignore\n","from sklearn.preprocessing import StandardScaler # type: ignore"]},{"cell_type":"code","source":["# 2.Tải bộ dữ liệu\n","# !gdown --id 1qiUDDoYyRLBiKOoYWdFl_5WByHE8Cugu"],"metadata":{"id":"CYt8AQR7Rkep"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"QOCimfFgavaW","executionInfo":{"status":"ok","timestamp":1731938003453,"user_tz":-420,"elapsed":2,"user":{"displayName":"Phuong Nguyen","userId":"11974806599025701743"}}},"outputs":[],"source":["# 3.Cài đặt giá trị ngẫu nhiên cố định\n","random_state = 59\n","np.random.seed(random_state)\n","torch.manual_seed(random_state)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(random_state)\n","\n","\n","# 4.Cài đặt thiết bị tính toán\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","# 5.Đọc dữ liệu\n","dataset_path = 'Auto_MPG_data.csv'\n","dataset = pd.read_csv(dataset_path, on_bad_lines='skip', sep=',')\n","\n","\n","# 6.Tiền xử lý bộ dữ liệu\n","\n","# Tách đặc trưng X và nhãn y\n","X = dataset.drop(columns='MPG').values\n","y = dataset['MPG'].values\n","\n","# Chia bộ dữ liệu train/val/test\n","val_size = 0.2\n","test_size = 0.125\n","is_shuffle = True\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=val_size, random_state=random_state, shuffle=is_shuffle)\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_size, random_state=random_state, shuffle=is_shuffle)\n","\n","# Chuẩn hóa đặc trưng đầu vào\n","normalizer = StandardScaler()\n","X_train = normalizer.fit_transform(X_train)\n","X_val = normalizer.transform(X_val)\n","X_test = normalizer.transform(X_test)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_val = torch.tensor(X_val, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.float32)\n","y_val = torch.tensor(y_val, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32)\n","\n","# 7. Xây dựng DataLoader\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.y)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","# khai báo luôn tham số batch size\n","batch_size = 32\n","train_dataset = CustomDataset(X_train, y_train)\n","val_dataset = CustomDataset(X_val, y_val)\n","train_loader = DataLoader(\n","                        train_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=True)\n","val_loader = DataLoader(\n","                        val_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=False)\n","\n","\n","# 8.Xây dựng mạng MLP\n","class MLP(nn.Module):\n","    def __init__(self, input_dims, hidden_dims, output_dims):\n","        super().__init__()\n","        self.linear1 = nn.Linear(input_dims, hidden_dims)\n","        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n","        self.output = nn.Linear(hidden_dims, output_dims)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = F.relu(x)\n","        x = self.linear2(x)\n","        x = F.relu(x)\n","        out = self.output(x)\n","        return out.squeeze(1)\n","\n","# khai báo một đối tượng của class\n","input_dims = X_train.shape[1]\n","output_dims = 1\n","hidden_dims = 64\n","model = MLP(\n","            input_dims = input_dims,\n","            hidden_dims = hidden_dims,\n","            output_dims = output_dims).to(device)\n","\n","\n","# 9.Khai báo hàm loss và optimizer\n","lr = 1e-2\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","\n","\n","# 10.Xây dựng hàm tính điểm R2\n","def r_squared(y_true, y_pred):\n","    y_true = torch.Tensor(y_true).to(device)\n","    y_pred = torch.Tensor(y_pred).to(device)\n","    mean_true = torch.mean(y_true)\n","    ss_tot = torch.sum((y_true - mean_true)**2)\n","    ss_res = torch.sum((y_true - y_pred) ** 2)\n","    r2 = 1 - (ss_res / ss_tot)\n","    return r2"]},{"cell_type":"code","source":["# 11.Huấn luyện mô hình\n","epochs = 20\n","train_losses = []\n","val_losses = []\n","train_r2 = []\n","val_r2 = []\n","\n","for epoch in range(epochs):\n","    train_loss = 0.0\n","    train_target = []\n","    val_target = []\n","    train_predict = []\n","    val_predict = []\n","    model.train()\n","    for X_samples, y_samples in train_loader:\n","        X_samples = X_samples.to(device)\n","        y_samples = y_samples.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(X_samples)\n","        train_predict += outputs.tolist()\n","        train_target += y_samples.tolist()\n","        loss = criterion(outputs, y_samples)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader)\n","    train_losses.append(train_loss)\n","    train_r2.append(r_squared(train_target, train_predict))\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for X_samples, y_samples in val_loader:\n","            X_samples = X_samples.to(device)\n","            y_samples = y_samples.to(device)\n","            outputs = model(X_samples)\n","            val_predict += outputs.tolist()\n","            val_target += y_samples.tolist()\n","            loss = criterion(outputs, y_samples)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","    val_losses.append(val_loss)\n","    val_r2.append(r_squared(val_target, val_predict))\n","    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}')\n","\n","\n","# 12.Đánh giá mô hình\n","model.eval()\n","with torch.no_grad():\n","    y_hat = model(X_test)\n","    test_set_r2 = r_squared(y_test, y_hat)\n","    print('Evaluation on test set: ')\n","    print(f'R2: {test_set_r2}')"],"metadata":{"id":"cSGUB83BN5rJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731938008481,"user_tz":-420,"elapsed":501,"user":{"displayName":"Phuong Nguyen","userId":"11974806599025701743"}},"outputId":"3ea316c0-44ab-4698-f4da-a9baee0ec4e1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Train Loss: 282.769, Val Loss: 88.672\n","Epoch 2/20, Train Loss: 137.669, Val Loss: 72.346\n","Epoch 3/20, Train Loss: 71.007, Val Loss: 19.143\n","Epoch 4/20, Train Loss: 25.083, Val Loss: 196.176\n","Epoch 5/20, Train Loss: 96.139, Val Loss: 20.444\n","Epoch 6/20, Train Loss: 17.765, Val Loss: 9.444\n","Epoch 7/20, Train Loss: 18.486, Val Loss: 14.535\n","Epoch 8/20, Train Loss: 37.859, Val Loss: 37.427\n","Epoch 9/20, Train Loss: 17.133, Val Loss: 38.134\n","Epoch 10/20, Train Loss: 22.991, Val Loss: 41.183\n","Epoch 11/20, Train Loss: 26.723, Val Loss: 20.063\n","Epoch 12/20, Train Loss: 9.852, Val Loss: 5.594\n","Epoch 13/20, Train Loss: 15.143, Val Loss: 16.025\n","Epoch 14/20, Train Loss: 12.213, Val Loss: 12.023\n","Epoch 15/20, Train Loss: 14.222, Val Loss: 7.731\n","Epoch 16/20, Train Loss: 10.845, Val Loss: 18.904\n","Epoch 17/20, Train Loss: 12.312, Val Loss: 14.885\n","Epoch 18/20, Train Loss: 15.474, Val Loss: 12.354\n","Epoch 19/20, Train Loss: 13.783, Val Loss: 5.380\n","Epoch 20/20, Train Loss: 7.285, Val Loss: 5.100\n","Evaluation on test set: \n","R2: 0.8835617899894714\n"]}]},{"cell_type":"markdown","metadata":{"id":"YKiyrCePDJmV"},"source":["## Câu hỏi trắc nghiệm"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Mtcq6uoyTvC","outputId":"792dd9a4-7979-4812-b8f6-6ac1e88c0b14","executionInfo":{"status":"ok","timestamp":1731938083989,"user_tz":-420,"elapsed":343,"user":{"displayName":"Phuong Nguyen","userId":"11974806599025701743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Train Loss: 519.211, Val Loss: 436.727\n","Epoch 2/20, Train Loss: 356.768, Val Loss: 310.773\n","Epoch 3/20, Train Loss: 249.179, Val Loss: 222.140\n","Epoch 4/20, Train Loss: 177.410, Val Loss: 159.997\n","Epoch 5/20, Train Loss: 128.735, Val Loss: 116.927\n","Epoch 6/20, Train Loss: 90.269, Val Loss: 85.884\n","Epoch 7/20, Train Loss: 68.482, Val Loss: 64.860\n","Epoch 8/20, Train Loss: 50.737, Val Loss: 49.201\n","Epoch 9/20, Train Loss: 41.014, Val Loss: 37.912\n","Epoch 10/20, Train Loss: 32.396, Val Loss: 30.654\n","Epoch 11/20, Train Loss: 25.552, Val Loss: 24.609\n","Epoch 12/20, Train Loss: 22.205, Val Loss: 20.082\n","Epoch 13/20, Train Loss: 18.990, Val Loss: 17.193\n","Epoch 14/20, Train Loss: 17.377, Val Loss: 15.012\n","Epoch 15/20, Train Loss: 16.494, Val Loss: 13.892\n","Epoch 16/20, Train Loss: 14.978, Val Loss: 12.466\n","Epoch 17/20, Train Loss: 15.892, Val Loss: 12.055\n","Epoch 18/20, Train Loss: 13.987, Val Loss: 11.341\n","Epoch 19/20, Train Loss: 13.200, Val Loss: 10.778\n","Epoch 20/20, Train Loss: 13.355, Val Loss: 10.108\n","Evaluation on test set for Linear Regression: R2: 0.8012855052947998\n"]}],"source":["# Câu 8.1 : Linear Regression (Không sử dụng hàm kích hoạt)\n","\n","# Điều chỉnh kiến trúc MLP thành Linear Regression (không sử dụng hàm kích hoạt)\n","class LinearRegressionModel(nn.Module):\n","    def __init__(self, input_dims, output_dims):\n","        super().__init__()\n","        self.linear = nn.Linear(input_dims, output_dims)\n","\n","    def forward(self, x):\n","        return self.linear(x).squeeze(1)  # Output không có hàm kích hoạt\n","\n","# Khai báo mô hình Linear Regression\n","model_lr = LinearRegressionModel(input_dims=input_dims, output_dims=output_dims).to(device)\n","\n","# Khai báo hàm loss và optimizer cho Linear Regression\n","optimizer_lr = torch.optim.SGD(model_lr.parameters(), lr=lr)\n","\n","# Huấn luyện mô hình Linear Regression\n","train_losses_lr = []\n","val_losses_lr = []\n","train_r2_lr = []\n","val_r2_lr = []\n","\n","for epoch in range(epochs):\n","    train_loss = 0.0\n","    train_target = []\n","    val_target = []\n","    train_predict = []\n","    val_predict = []\n","    model_lr.train()\n","    for X_samples, y_samples in train_loader:\n","        X_samples = X_samples.to(device)\n","        y_samples = y_samples.to(device)\n","        optimizer_lr.zero_grad()\n","        outputs = model_lr(X_samples)\n","        train_predict += outputs.tolist()\n","        train_target += y_samples.tolist()\n","        loss = criterion(outputs, y_samples)\n","        loss.backward()\n","        optimizer_lr.step()\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader)\n","    train_losses_lr.append(train_loss)\n","    train_r2_lr.append(r_squared(train_target, train_predict))\n","    model_lr.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for X_samples, y_samples in val_loader:\n","            X_samples = X_samples.to(device)\n","            y_samples = y_samples.to(device)\n","            outputs = model_lr(X_samples)\n","            val_predict += outputs.tolist()\n","            val_target += y_samples.tolist()\n","            loss = criterion(outputs, y_samples)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","    val_losses_lr.append(val_loss)\n","    val_r2_lr.append(r_squared(val_target, val_predict))\n","    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}')\n","\n","# Đánh giá mô hình Linear Regression trên tập test\n","model_lr.eval()\n","with torch.no_grad():\n","    y_hat_lr = model_lr(X_test)\n","    test_set_r2_lr = r_squared(y_test, y_hat_lr)\n","    print(f'Evaluation on test set for Linear Regression: R2: {test_set_r2_lr}')\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vSnWXm1d_l9_","outputId":"1baa00ce-f8e7-4c20-f82e-d120c0ba5784","executionInfo":{"status":"ok","timestamp":1731938420832,"user_tz":-420,"elapsed":862,"user":{"displayName":"Phuong Nguyen","userId":"11974806599025701743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Train Loss: 153.980, Val Loss: 52.652\n","Epoch 2/20, Train Loss: 47.394, Val Loss: 37.862\n","Epoch 3/20, Train Loss: 35.761, Val Loss: 28.605\n","Epoch 4/20, Train Loss: 25.665, Val Loss: 16.337\n","Epoch 5/20, Train Loss: 19.496, Val Loss: 10.216\n","Epoch 6/20, Train Loss: 17.013, Val Loss: 8.232\n","Epoch 7/20, Train Loss: 14.849, Val Loss: 7.465\n","Epoch 8/20, Train Loss: 14.112, Val Loss: 9.234\n","Epoch 9/20, Train Loss: 13.321, Val Loss: 7.253\n","Epoch 10/20, Train Loss: 12.945, Val Loss: 7.206\n","Epoch 11/20, Train Loss: 12.007, Val Loss: 8.929\n","Epoch 12/20, Train Loss: 12.153, Val Loss: 9.120\n","Epoch 13/20, Train Loss: 12.441, Val Loss: 8.774\n","Epoch 14/20, Train Loss: 12.169, Val Loss: 12.103\n","Epoch 15/20, Train Loss: 12.201, Val Loss: 6.851\n","Epoch 16/20, Train Loss: 11.218, Val Loss: 6.669\n","Epoch 17/20, Train Loss: 11.491, Val Loss: 6.968\n","Epoch 18/20, Train Loss: 11.668, Val Loss: 7.663\n","Epoch 19/20, Train Loss: 10.579, Val Loss: 6.361\n","Epoch 20/20, Train Loss: 11.354, Val Loss: 6.383\n","Evaluation on test set for Sigmoid: R2: 0.836987316608429\n"]}],"source":["# Câu 8.2 : Sử dụng hàm kích hoạt Sigmoid\n","\n","# Điều chỉnh hàm kích hoạt thành Sigmoid\n","class MLP_Sigmoid(nn.Module):\n","    def __init__(self, input_dims, hidden_dims, output_dims):\n","        super().__init__()\n","        self.linear1 = nn.Linear(input_dims, hidden_dims)\n","        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n","        self.output = nn.Linear(hidden_dims, output_dims)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = torch.sigmoid(x)  # Sử dụng hàm kích hoạt Sigmoid\n","        x = self.linear2(x)\n","        x = torch.sigmoid(x)  # Sử dụng hàm kích hoạt Sigmoid\n","        out = self.output(x)\n","        return out.squeeze(1)\n","\n","# Khai báo mô hình với Sigmoid\n","model_sigmoid = MLP_Sigmoid(input_dims=input_dims, hidden_dims=hidden_dims, output_dims=output_dims).to(device)\n","\n","# Khai báo hàm loss và optimizer cho MLP Sigmoid\n","optimizer_sigmoid = torch.optim.SGD(model_sigmoid.parameters(), lr=lr)\n","\n","# Huấn luyện mô hình với hàm kích hoạt Sigmoid\n","train_losses_sigmoid = []\n","val_losses_sigmoid = []\n","train_r2_sigmoid = []\n","val_r2_sigmoid = []\n","\n","for epoch in range(epochs):\n","    train_loss = 0.0\n","    train_target = []\n","    val_target = []\n","    train_predict = []\n","    val_predict = []\n","    model_sigmoid.train()\n","    for X_samples, y_samples in train_loader:\n","        X_samples = X_samples.to(device)\n","        y_samples = y_samples.to(device)\n","        optimizer_sigmoid.zero_grad()\n","        outputs = model_sigmoid(X_samples)\n","        train_predict += outputs.tolist()\n","        train_target += y_samples.tolist()\n","        loss = criterion(outputs, y_samples)\n","        loss.backward()\n","        optimizer_sigmoid.step()\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader)\n","    train_losses_sigmoid.append(train_loss)\n","    train_r2_sigmoid.append(r_squared(train_target, train_predict))\n","    model_sigmoid.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for X_samples, y_samples in val_loader:\n","            X_samples = X_samples.to(device)\n","            y_samples = y_samples.to(device)\n","            outputs = model_sigmoid(X_samples)\n","            val_predict += outputs.tolist()\n","            val_target += y_samples.tolist()\n","            loss = criterion(outputs, y_samples)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","    val_losses_sigmoid.append(val_loss)\n","    val_r2_sigmoid.append(r_squared(val_target, val_predict))\n","    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}')\n","\n","# Đánh giá mô hình Sigmoid trên tập test\n","model_sigmoid.eval()\n","with torch.no_grad():\n","    y_hat_sigmoid = model_sigmoid(X_test)\n","    test_set_r2_sigmoid = r_squared(y_test, y_hat_sigmoid)\n","    print(f'Evaluation on test set for Sigmoid: R2: {test_set_r2_sigmoid}')\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqGHvh2kAQ6M","outputId":"b0c42ef6-07b4-4bec-8360-3aa3a0d38eec","executionInfo":{"status":"ok","timestamp":1731938504837,"user_tz":-420,"elapsed":975,"user":{"displayName":"Phuong Nguyen","userId":"11974806599025701743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Train Loss: 229.109, Val Loss: 74.251\n","Epoch 2/20, Train Loss: 25.180, Val Loss: 8.916\n","Epoch 3/20, Train Loss: 17.625, Val Loss: 10.553\n","Epoch 4/20, Train Loss: 13.618, Val Loss: 7.745\n","Epoch 5/20, Train Loss: 11.973, Val Loss: 8.701\n","Epoch 6/20, Train Loss: 11.126, Val Loss: 7.141\n","Epoch 7/20, Train Loss: 11.149, Val Loss: 5.337\n","Epoch 8/20, Train Loss: 9.696, Val Loss: 8.109\n","Epoch 9/20, Train Loss: 9.603, Val Loss: 6.747\n","Epoch 10/20, Train Loss: 8.458, Val Loss: 6.038\n","Epoch 11/20, Train Loss: 8.329, Val Loss: 5.067\n","Epoch 12/20, Train Loss: 8.272, Val Loss: 5.081\n","Epoch 13/20, Train Loss: 8.251, Val Loss: 5.481\n","Epoch 14/20, Train Loss: 8.314, Val Loss: 6.373\n","Epoch 15/20, Train Loss: 7.679, Val Loss: 5.615\n","Epoch 16/20, Train Loss: 7.589, Val Loss: 6.847\n","Epoch 17/20, Train Loss: 8.399, Val Loss: 5.784\n","Epoch 18/20, Train Loss: 7.942, Val Loss: 12.657\n","Epoch 19/20, Train Loss: 9.215, Val Loss: 5.368\n","Epoch 20/20, Train Loss: 7.401, Val Loss: 5.251\n","Evaluation on test set for Tanh: R2: 0.887295663356781\n"]}],"source":["# Câu 8.3 : Sử dụng hàm kích hoạt Tanh\n","\n","# Điều chỉnh hàm kích hoạt thành Tanh\n","class MLP_Tanh(nn.Module):\n","    def __init__(self, input_dims, hidden_dims, output_dims):\n","        super().__init__()\n","        self.linear1 = nn.Linear(input_dims, hidden_dims)\n","        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n","        self.output = nn.Linear(hidden_dims, output_dims)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = torch.tanh(x)  # Sử dụng hàm kích hoạt Tanh\n","        x = self.linear2(x)\n","        x = torch.tanh(x)  # Sử dụng hàm kích hoạt Tanh\n","        out = self.output(x)\n","        return out.squeeze(1)\n","\n","# Khai báo mô hình với Tanh\n","model_tanh = MLP_Tanh(input_dims=input_dims, hidden_dims=hidden_dims, output_dims=output_dims).to(device)\n","\n","# Khai báo hàm loss và optimizer cho MLP Tanh\n","optimizer_tanh = torch.optim.SGD(model_tanh.parameters(), lr=lr)\n","\n","# Huấn luyện mô hình với hàm kích hoạt Tanh\n","train_losses_tanh = []\n","val_losses_tanh = []\n","train_r2_tanh = []\n","val_r2_tanh = []\n","\n","for epoch in range(epochs):\n","    train_loss = 0.0\n","    train_target = []\n","    val_target = []\n","    train_predict = []\n","    val_predict = []\n","    model_tanh.train()\n","    for X_samples, y_samples in train_loader:\n","        X_samples = X_samples.to(device)\n","        y_samples = y_samples.to(device)\n","        optimizer_tanh.zero_grad()\n","        outputs = model_tanh(X_samples)\n","        train_predict += outputs.tolist()\n","        train_target += y_samples.tolist()\n","        loss = criterion(outputs, y_samples)\n","        loss.backward()\n","        optimizer_tanh.step()\n","        train_loss += loss.item()\n","    train_loss /= len(train_loader)\n","    train_losses_tanh.append(train_loss)\n","    train_r2_tanh.append(r_squared(train_target, train_predict))\n","    model_tanh.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for X_samples, y_samples in val_loader:\n","            X_samples = X_samples.to(device)\n","            y_samples = y_samples.to(device)\n","            outputs = model_tanh(X_samples)\n","            val_predict += outputs.tolist()\n","            val_target += y_samples.tolist()\n","            loss = criterion(outputs, y_samples)\n","            val_loss += loss.item()\n","    val_loss /= len(val_loader)\n","    val_losses_tanh.append(val_loss)\n","    val_r2_tanh.append(r_squared(val_target, val_predict))\n","    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}')\n","\n","# Đánh giá mô hình Tanh trên tập test\n","model_tanh.eval()\n","with torch.no_grad():\n","    y_hat_tanh = model_tanh(X_test)\n","    test_set_r2_tanh = r_squared(y_test, y_hat_tanh)\n","    print(f'Evaluation on test set for Tanh: R2: {test_set_r2_tanh}')\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}