{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ9E9yr97M2E"
   },
   "source": [
    "## Bài tập 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "96oDrcXueydg"
   },
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import random\n",
    "import math\n",
    "\n",
    "random.seed(0) # please do not remove this line\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j3VYnu7liS97"
   },
   "outputs": [],
   "source": [
    "def load_data_from_file(fileName = 'advertising.csv'):\n",
    "    data = np.genfromtxt(fileName, dtype=None, delimiter=',', skip_header=1)\n",
    "    features_X = data[:, :3]\n",
    "    sales_Y = data[:, 3]\n",
    "\n",
    "    intercept = np.ones((features_X.shape[0], 1))\n",
    "    features_X = np.concatenate((intercept, features_X), axis=1)\n",
    "\n",
    "    return features_X, sales_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-f_7uoJ5jQTE",
    "outputId": "edff431c-7541-4084-812b-c3f788594193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  230.1  37.8  69.2]\n",
      " [  1.   44.5  39.3  45.1]\n",
      " [  1.   17.2  45.9  69.3]\n",
      " [  1.  151.5  41.3  58.5]\n",
      " [  1.  180.8  10.8  58.4]]\n"
     ]
    }
   ],
   "source": [
    "features_X, _ = load_data_from_file()\n",
    "print(features_X[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORLPr_yDfAvM",
    "outputId": "c7918794-28e4-4d4b-9068-07c81007a1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "_, sales_Y = load_data_from_file()\n",
    "print(sales_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlGkccatjQWb",
    "outputId": "d8be00ae-b6cc-4b87-c435-96a4d858ad2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.444218515250481, 2.5795440294030247, -0.79428419169155, -2.4108324970703663]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_value(bound = 10):\n",
    "    return (random.random() - 0.5)*bound\n",
    "\n",
    "def create_individual(n=4, bound=10):\n",
    "    individual = [generate_random_value() for _ in range(n)]\n",
    "    return individual\n",
    "\n",
    "individual = create_individual()\n",
    "print(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfY3yF0VjQcb",
    "outputId": "347844f1-da54-4d3b-a923-ce376649e50b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0185991537088997e-06\n"
     ]
    }
   ],
   "source": [
    "features_X, sales_Y = load_data_from_file()\n",
    "def compute_loss(individual):\n",
    "    theta = np.array(individual)\n",
    "    y_hat = features_X.dot(theta)\n",
    "    loss = np.multiply((y_hat-sales_Y), (y_hat-sales_Y)).mean()\n",
    "    return loss\n",
    "\n",
    "def compute_fitness(individual):\n",
    "    loss = compute_loss(individual)\n",
    "    fitness = 1 / (loss + 1)\n",
    "    return fitness\n",
    "\n",
    "features_X, sales_Y = load_data_from_file()\n",
    "individual = [4.09, 4.82, 3.10, 4.02]\n",
    "fitness_score = compute_fitness(individual)\n",
    "print(fitness_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N87YpVGFjQfT",
    "outputId": "fee071ce-c945-4642-fd8a-2702b0d8eb77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individual1 [3.44, 2.57, -0.79, -2.41]\n",
      "individual2 [4.09, 4.82, 3.1, 4.02]\n"
     ]
    }
   ],
   "source": [
    "def crossover(individual1, individual2, crossover_rate=0.9):\n",
    "    individual1_new = individual1.copy()\n",
    "    individual2_new = individual2.copy()\n",
    "\n",
    "    for i in range(len(individual1)):\n",
    "        if random.random() < crossover_rate:\n",
    "            individual1_new[i] = individual2[i]\n",
    "            individual2_new[i] = individual1[i]\n",
    "\n",
    "    return individual1_new, individual2_new\n",
    "\n",
    "individual1 = [4.09, 4.82, 3.10, 4.02]\n",
    "individual2 = [3.44, 2.57, -0.79, -2.41]\n",
    "\n",
    "individual1, individual2 = crossover(individual1, individual2, 2.0)\n",
    "print('individual1', individual1)\n",
    "print('individual2', individual2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQZ0yt5fjQiE",
    "outputId": "9e2a0a14-978c-49fa-feb1-895b653b88f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def mutate(individual, mutation_rate=0.05):\n",
    "    individual_new = individual.copy()\n",
    "\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < mutation_rate:\n",
    "            individual_new[i] = generate_random_value()\n",
    "\n",
    "    return individual_new\n",
    "\n",
    "before_individual = [4.09, 4.82, 3.10, 4.02]\n",
    "after_individual = mutate(individual, mutation_rate =2.0)\n",
    "print(before_individual == after_individual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUsThzJ0jQlL",
    "outputId": "e1bceac5-d785-4d97-f3ae-133ddbdd35c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 123415.051528805 with chromsome:  [3.44, 2.57, -0.79, -2.41]\n"
     ]
    }
   ],
   "source": [
    "def initialize_population(m):\n",
    "    population = [create_individual() for _ in range(m)]\n",
    "    return population\n",
    "\n",
    "def selection(sorted_old_population, m):\n",
    "    index1 = random.randint(0, m-1)\n",
    "    while True:\n",
    "        index2 = random.randint(0, m-1)\n",
    "        if (index2 != index1):\n",
    "            break\n",
    "\n",
    "    individual_s = sorted_old_population[index1]\n",
    "    if index2 > index1:\n",
    "        individual_s = sorted_old_population[index2]\n",
    "\n",
    "    return individual_s\n",
    "\n",
    "def create_new_population(old_population, elitism=2, gen=1):\n",
    "    m = len(old_population)\n",
    "    sorted_population = sorted(old_population, key=compute_fitness)\n",
    "\n",
    "    if gen%1 == 0:\n",
    "        print(\"Best loss:\", compute_loss(sorted_population[m-1]), \"with chromsome: \", sorted_population[m-1])\n",
    "\n",
    "    new_population = []\n",
    "    while len(new_population) < m-elitism:\n",
    "        # selection\n",
    "        individual_s1 = selection(sorted_population, m)\n",
    "        individual_s2 = selection(sorted_population, m) # duplication\n",
    "\n",
    "        # crossover\n",
    "        individual_t1, individual_t2 = crossover(individual_s1, individual_s2)\n",
    "\n",
    "        # mutation\n",
    "        individual_m1 = mutate(individual_t1)\n",
    "        individual_m2 = mutate(individual_t2)\n",
    "\n",
    "        new_population.append(individual_m1)\n",
    "        new_population.append(individual_m2)\n",
    "\n",
    "    for ind in sorted_population[m-elitism:]:\n",
    "        new_population.append(ind.copy())\n",
    "\n",
    "    return new_population, compute_loss(sorted_population[m-1])\n",
    "\n",
    "individual1 = [4.09, 4.82, 3.10, 4.02]\n",
    "individual2 = [3.44, 2.57, -0.79, -2.41]\n",
    "old_population = [individual1, individual2]\n",
    "new_population, _ = create_new_population(old_population, elitism=2, gen=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Zkxn9Y0jQtr",
    "outputId": "76bcd839-0600-4cb6-bcf9-f68d15d612fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 74.32007006830223 with chromsome:  [4.451961254807838, 0.13120346518100345, -0.1654409943010282, -0.13322772840326458]\n",
      "Best loss: 74.32007006830223 with chromsome:  [4.451961254807838, 0.13120346518100345, -0.1654409943010282, -0.13322772840326458]\n",
      "Best loss: 74.32007006830223 with chromsome:  [4.451961254807838, 0.13120346518100345, -0.1654409943010282, -0.13322772840326458]\n",
      "Best loss: 74.32007006830223 with chromsome:  [4.451961254807838, 0.13120346518100345, -0.1654409943010282, -0.13322772840326458]\n",
      "Best loss: 65.04961316290488 with chromsome:  [-4.552115033103704, 0.05400453886839074, 0.6014920199489371, -0.1915479403096887]\n",
      "Best loss: 56.04071638727552 with chromsome:  [-3.216511334816883, 0.11510177554160839, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 56.04071638727552 with chromsome:  [-3.216511334816883, 0.11510177554160839, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 50.02242244600224 with chromsome:  [-2.7653761244405137, 0.11510177554160839, 0.06571769373241776, -0.13322772840326458]\n",
      "Best loss: 49.16837405354372 with chromsome:  [-4.60540315716801, 0.11510177554160839, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 49.16837405354372 with chromsome:  [-4.60540315716801, 0.11510177554160839, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 48.41108286582212 with chromsome:  [-4.832688310625666, 0.11510177554160839, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 40.29663381016013 with chromsome:  [0.31867962610622524, 0.11510177554160839, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 18.844805339782052 with chromsome:  [2.0000088201181097, 0.05400453886839074, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 18.844805339782052 with chromsome:  [2.0000088201181097, 0.05400453886839074, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 18.844805339782052 with chromsome:  [2.0000088201181097, 0.05400453886839074, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 18.844805339782052 with chromsome:  [2.0000088201181097, 0.05400453886839074, 0.37230409406354803, -0.13322772840326458]\n",
      "Best loss: 15.688627204371043 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 15.688627204371043 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 15.688627204371043 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 15.688627204371043 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 15.688627204371043 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 15.688627204371043 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 15.688627204371043 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 11.821209276994646 with chromsome:  [4.451961254807838, 0.07090408547756999, 0.17415266509128058, -0.13322772840326458]\n",
      "Best loss: 9.53710185360813 with chromsome:  [4.451961254807838, 0.07090408547756999, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 9.53710185360813 with chromsome:  [4.451961254807838, 0.07090408547756999, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 5.253083710873718 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 5.253083710873718 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 5.253083710873718 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 5.253083710873718 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 5.253083710873718 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 5.253083710873718 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 5.253083710873718 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.17415266509128058, -0.07132050586352245]\n",
      "Best loss: 4.022780210480929 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 4.022780210480929 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 4.022780210480929 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 4.022780210480929 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 4.022780210480929 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 4.022780210480929 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 4.022780210480929 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 3.651312427090141 with chromsome:  [4.0485485962463255, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 3.651312427090141 with chromsome:  [4.0485485962463255, 0.05400453886839074, 0.17415266509128058, -0.02133266448619997]\n",
      "Best loss: 3.1540643023212453 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.02133266448619997]\n",
      "Best loss: 3.1540643023212453 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.02133266448619997]\n",
      "Best loss: 3.1540643023212453 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.02133266448619997]\n",
      "Best loss: 3.1540643023212453 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.02133266448619997]\n",
      "Best loss: 3.1540643023212453 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.02133266448619997]\n",
      "Best loss: 3.1540643023212453 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.02133266448619997]\n",
      "Best loss: 3.0367924525575023 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.14267923850603936, -0.02133266448619997]\n",
      "Best loss: 3.0367924525575023 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.14267923850603936, -0.02133266448619997]\n",
      "Best loss: 3.0367924525575023 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.14267923850603936, -0.02133266448619997]\n",
      "Best loss: 3.0367924525575023 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.14267923850603936, -0.02133266448619997]\n",
      "Best loss: 3.0367924525575023 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.14267923850603936, -0.02133266448619997]\n",
      "Best loss: 3.0367924525575023 with chromsome:  [4.451961254807838, 0.05400453886839074, 0.14267923850603936, -0.02133266448619997]\n",
      "Best loss: 2.8661475230082543 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.013983731227984464]\n",
      "Best loss: 2.8661475230082543 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.013983731227984464]\n",
      "Best loss: 2.8661475230082543 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.013983731227984464]\n",
      "Best loss: 2.8661475230082543 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.013983731227984464]\n",
      "Best loss: 2.8661475230082543 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.10839611313515629, -0.013983731227984464]\n",
      "Best loss: 2.798178915291677 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11946270476752008, -0.013983731227984464]\n",
      "Best loss: 2.798178915291677 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11946270476752008, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7979706698656126 with chromsome:  [4.840465090634472, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7958497076452393 with chromsome:  [4.950208885777033, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7958497076452393 with chromsome:  [4.950208885777033, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7958497076452393 with chromsome:  [4.950208885777033, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7958497076452393 with chromsome:  [4.950208885777033, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7958497076452393 with chromsome:  [4.950208885777033, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7949273507653145 with chromsome:  [4.938488520743825, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.79421945178201 with chromsome:  [4.925336566100046, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.79421945178201 with chromsome:  [4.925336566100046, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.79421945178201 with chromsome:  [4.925336566100046, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n",
      "Best loss: 2.7938059630209295 with chromsome:  [4.904721484897376, 0.05400453886839074, 0.11656620894137215, -0.013983731227984464]\n"
     ]
    }
   ],
   "source": [
    "def run_ga():\n",
    "    n_generations = 100\n",
    "    m = 600\n",
    "    features_X, sales_Y = load_data_from_file()\n",
    "    population = initialize_population(m)\n",
    "    losses_list = []\n",
    "    for i in range(n_generations):\n",
    "        population, losses = create_new_population(population, 2, i)\n",
    "        losses_list.append(losses)\n",
    "    return losses_list\n",
    "\n",
    "losses_list = run_ga()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LWeCyswRwcLS",
    "outputId": "d3563c1a-0bbc-40e5-b6de-0653d31d6cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 596.9254438322097 with chromsome:  [-2.8341050786135416, -0.07692741968139294, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 252.41681604580742 with chromsome:  [3.742396899939634, 0.17421001894963983, 0.29191915510180966, -0.5909327327227654]\n",
      "Best loss: 252.41681604580742 with chromsome:  [3.742396899939634, 0.17421001894963983, 0.29191915510180966, -0.5909327327227654]\n",
      "Best loss: 252.41681604580742 with chromsome:  [3.742396899939634, 0.17421001894963983, 0.29191915510180966, -0.5909327327227654]\n",
      "Best loss: 236.2515727658435 with chromsome:  [3.742396899939634, 0.17421001894963983, 0.29191915510180966, -0.4557459703164446]\n",
      "Best loss: 236.2515727658435 with chromsome:  [3.742396899939634, 0.17421001894963983, 0.29191915510180966, -0.4557459703164446]\n",
      "Best loss: 236.2515727658435 with chromsome:  [3.742396899939634, 0.17421001894963983, 0.29191915510180966, -0.4557459703164446]\n",
      "Best loss: 27.208820876817537 with chromsome:  [-2.8341050786135416, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 27.208820876817537 with chromsome:  [-2.8341050786135416, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 27.208820876817537 with chromsome:  [-2.8341050786135416, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 18.964726445065573 with chromsome:  [-1.5613182552774496, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 18.964726445065573 with chromsome:  [-1.5613182552774496, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 16.077015502749035 with chromsome:  [-0.9298394506158048, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 16.077015502749035 with chromsome:  [-0.9298394506158048, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 16.077015502749035 with chromsome:  [-0.9298394506158048, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 14.158141938491092 with chromsome:  [-0.36085852820021525, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 12.219071826950103 with chromsome:  [0.8801905402245136, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 12.219071826950103 with chromsome:  [0.8801905402245136, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 12.219071826950103 with chromsome:  [0.8801905402245136, 0.04308869610617605, 0.19761201659920347, 0.10330877348332823]\n",
      "Best loss: 8.630097019372238 with chromsome:  [2.6157408358238268, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 8.630097019372238 with chromsome:  [2.6157408358238268, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 5.536480372317912 with chromsome:  [0.7407763920601973, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 5.536480372317912 with chromsome:  [0.7407763920601973, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 5.536480372317912 with chromsome:  [0.7407763920601973, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 5.536480372317912 with chromsome:  [0.7407763920601973, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 5.524547897470495 with chromsome:  [0.8801905402245136, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 5.523861883363274 with chromsome:  [0.8594625555602131, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 5.523861883363274 with chromsome:  [0.8594625555602131, 0.06346056845480508, 0.19761201659920347, 0.011408485908858124]\n",
      "Best loss: 4.266980856382681 with chromsome:  [2.8338350878705096, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 4.266980856382681 with chromsome:  [2.8338350878705096, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.9998389320133105 with chromsome:  [4.430392595922392, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.9998389320133105 with chromsome:  [4.430392595922392, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.6907632837446367 with chromsome:  [4.164776436638402, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.6907632837446367 with chromsome:  [4.164776436638402, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.6518624964032758 with chromsome:  [3.3124137285131585, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.546029672578096 with chromsome:  [3.4773054606014053, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.546029672578096 with chromsome:  [3.4773054606014053, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.499353400153891 with chromsome:  [3.6148213454343825, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.499353400153891 with chromsome:  [3.6148213454343825, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.4910970879549494 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07456794996454019, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.46806349903874 with chromsome:  [3.7597696598885855, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4642122617267352 with chromsome:  [3.449848208755011, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4642122617267352 with chromsome:  [3.449848208755011, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4642122617267352 with chromsome:  [3.449848208755011, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4642122617267352 with chromsome:  [3.449848208755011, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4642122617267352 with chromsome:  [3.449848208755011, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4507547333383344 with chromsome:  [3.5054920679234556, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4507547333383344 with chromsome:  [3.5054920679234556, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4507547333383344 with chromsome:  [3.5054920679234556, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.4507547333383344 with chromsome:  [3.5054920679234556, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.447844824642244 with chromsome:  [3.6744796454931175, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.447844824642244 with chromsome:  [3.6744796454931175, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.447844824642244 with chromsome:  [3.6744796454931175, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.442421345505045 with chromsome:  [3.5802955220421384, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.442421345505045 with chromsome:  [3.5802955220421384, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.442421345505045 with chromsome:  [3.5802955220421384, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.442421345505045 with chromsome:  [3.5802955220421384, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.442421345505045 with chromsome:  [3.5802955220421384, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.442421345505045 with chromsome:  [3.5802955220421384, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.442421345505045 with chromsome:  [3.5802955220421384, 0.06346056845480508, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.3632134112373135 with chromsome:  [3.5054920679234556, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.3632134112373135 with chromsome:  [3.5054920679234556, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.3632134112373135 with chromsome:  [3.5054920679234556, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.306724919625411 with chromsome:  [3.5802955220421384, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.251516890598782 with chromsome:  [3.6744796454931175, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.251516890598782 with chromsome:  [3.6744796454931175, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.251516890598782 with chromsome:  [3.6744796454931175, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.1910089956568117 with chromsome:  [3.918248869350709, 0.06127155819411367, 0.07960491736679676, 0.011408485908858124]\n",
      "Best loss: 3.1150067486208544 with chromsome:  [3.5802955220421384, 0.06127155819411367, 0.09779133219433134, 0.011408485908858124]\n",
      "Best loss: 3.1150067486208544 with chromsome:  [3.5802955220421384, 0.06127155819411367, 0.09779133219433134, 0.011408485908858124]\n",
      "Best loss: 3.1150067486208544 with chromsome:  [3.5802955220421384, 0.06127155819411367, 0.09779133219433134, 0.011408485908858124]\n",
      "Best loss: 3.1150067486208544 with chromsome:  [3.5802955220421384, 0.06127155819411367, 0.09779133219433134, 0.011408485908858124]\n",
      "Best loss: 3.1150067486208544 with chromsome:  [3.5802955220421384, 0.06127155819411367, 0.09779133219433134, 0.011408485908858124]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(losses_list):\n",
    "    plt.plot(losses_list, c='green')\n",
    "    plt.xlabel('Generations')\n",
    "    plt.ylabel('losses')\n",
    "    plt.show()\n",
    "\n",
    "losses_list = run_ga()\n",
    "visualize_loss(losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "UtMXyuaH9O3l",
    "outputId": "1e0c2f33-ce53-4b9a-d6b9-3a23d07f0648"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'population' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f640a99466f0>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mvisualize_predict_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-f640a99466f0>\u001b[0m in \u001b[0;36mvisualize_predict_gt\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_predict_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# visualization of ground truth and predict value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msorted_population\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_fitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_population\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'population' is not defined"
     ]
    }
   ],
   "source": [
    "def visualize_predict_gt():\n",
    "    global population\n",
    "    # visualization of ground truth and predict value\n",
    "    sorted_population = sorted(population, key=compute_fitness)\n",
    "    print(sorted_population[-1])\n",
    "    theta = np.array(sorted_population[-1])\n",
    "\n",
    "    estimated_prices = []\n",
    "    for feature in features_X:\n",
    "        estimated_price = sum(c*x for x, c in zip(feature, theta))\n",
    "        estimated_prices.append(estimated_price)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.xlabel('Samples')\n",
    "    plt.ylabel('Price')\n",
    "    plt.plot(sales_Y, c='green', label='Real Prices')\n",
    "    plt.plot(estimated_prices, c='blue', label='Estimated Prices')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predict_gt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcpOdcXDtMNB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
